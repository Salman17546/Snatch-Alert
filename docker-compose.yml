services:
  # ============================================================================
  # DATABASE
  # ============================================================================
  postgres:
    image: postgres:15-alpine
    container_name: snatchalert_db
    environment:
      POSTGRES_DB: ${DB_NAME:-snatchalertdb}
      POSTGRES_USER: ${DB_USER:-snatch_user}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-SnatchAlert123}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - "./Facebook Scraper/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql"
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-snatch_user} -d ${DB_NAME:-snatchalertdb}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # ============================================================================
  # REDIS (for Celery)
  # ============================================================================
  redis:
    image: redis:7-alpine
    container_name: snatchalert_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # ============================================================================
  # SNATCHALERT DJANGO API
  # ============================================================================
  snatchalert_api:
    build:
      context: ./SnatchAlert/SnatchAlert
      dockerfile: Dockerfile
    container_name: snatchalert_api
    environment:
      - SECRET_KEY=${SECRET_KEY:-django-insecure-change-this-in-production}
      - DEBUG=${DEBUG:-False}
      - ALLOWED_HOSTS=${ALLOWED_HOSTS:-localhost,127.0.0.1,snatchalert_api}
      - DB_ENGINE=django.db.backends.postgresql
      - DB_NAME=${DB_NAME:-snatchalertdb}
      - DB_USER=${DB_USER:-snatch_user}
      - DB_PASSWORD=${DB_PASSWORD:-SnatchAlert123}
      - DB_HOST=postgres
      - DB_PORT=5432
      - CORS_ALLOW_ALL_ORIGINS=${CORS_ALLOW_ALL_ORIGINS:-True}
    volumes:
      - snatchalert_static:/app/staticfiles
      - snatchalert_media:/app/media
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: >
      sh -c "python manage.py migrate --noinput &&
             gunicorn --bind 0.0.0.0:8000 --workers 3 SnatchAlert.wsgi:application"

  # ============================================================================
  # CRIME SCRAPER - CELERY WORKER
  # ============================================================================
  scraper_worker:
    build:
      context: "./Facebook Scraper"
      dockerfile: Dockerfile
    container_name: snatchalert_scraper_worker
    command: celery -A scraper_integration.celery_app worker --loglevel=info
    environment:
      - DB_NAME=${DB_NAME:-snatchalertdb}
      - DB_USER=${DB_USER:-snatch_user}
      - DB_PASSWORD=${DB_PASSWORD:-SnatchAlert123}
      - DB_HOST=postgres
      - DB_PORT=5432
      - REDIS_URL=redis://redis:6379/0
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - GOOGLE_MAPS_API_KEY=${GOOGLE_MAPS_API_KEY}
      - FB_EMAIL=${FB_EMAIL}
      - FB_PASSWORD=${FB_PASSWORD}
      - FB_GRAPH_API_ACCESS_TOKEN=${FB_GRAPH_API_ACCESS_TOKEN}
      - TWITTER_BEARER_TOKEN=${TWITTER_BEARER_TOKEN}
      - SCRAPER_TARGET_INCIDENTS=${SCRAPER_TARGET_INCIDENTS:-50}
      - SCRAPER_SCHEDULE_HOURS=${SCRAPER_SCHEDULE_HOURS:-12}
    volumes:
      - scraper_logs:/app/logs
      - scraper_output:/app/output
      - scraper_data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  # ============================================================================
  # CRIME SCRAPER - CELERY BEAT (SCHEDULER)
  # ============================================================================
  scraper_beat:
    build:
      context: "./Facebook Scraper"
      dockerfile: Dockerfile
    container_name: snatchalert_scraper_beat
    command: celery -A scraper_integration.celery_app beat --loglevel=info
    environment:
      - DB_NAME=${DB_NAME:-snatchalertdb}
      - DB_USER=${DB_USER:-snatch_user}
      - DB_PASSWORD=${DB_PASSWORD:-SnatchAlert123}
      - DB_HOST=postgres
      - DB_PORT=5432
      - REDIS_URL=redis://redis:6379/0
      - SCRAPER_TARGET_INCIDENTS=${SCRAPER_TARGET_INCIDENTS:-50}
      - SCRAPER_SCHEDULE_HOURS=${SCRAPER_SCHEDULE_HOURS:-12}
    volumes:
      - scraper_logs:/app/logs
    depends_on:
      - scraper_worker
    restart: unless-stopped

  # ============================================================================
  # NGINX REVERSE PROXY (Optional - for production)
  # ============================================================================
  nginx:
    image: nginx:alpine
    container_name: snatchalert_nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - snatchalert_static:/app/staticfiles:ro
      - snatchalert_media:/app/media:ro
    depends_on:
      - snatchalert_api
    restart: unless-stopped
    profiles:
      - production

volumes:
  postgres_data:
  redis_data:
  snatchalert_static:
  snatchalert_media:
  scraper_logs:
  scraper_output:
  scraper_data:
